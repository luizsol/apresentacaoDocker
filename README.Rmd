---
title: "*Docker*: o que é e para que serve"
author: Luiz Sol e Marcos Vinicius
date: 2019-03-11
output:
  beamer_presentation:
    theme: "AnnArbor"
    colortheme: "dolphin"
    fonttheme: "structurebold"
---

# O problema

A pessoa $A$ desenvolveu um *pipeline* de *Machile Leearning* em Python no seu computador pessoal.

---

O *setup* da pessoa $A$ é:

* Majaro 17.1 (Arch Linux)
* Python 3.5

* PostgreSQL 10.3 (Banco de Dados)
* PyTorch 0.9
* Pandas 0.14

---

Agora a pessoa $B$ precisa revisar o código (ver se foi bem escrito e se funciona corretamente).

---

O *setup* da pessoa $B$ é:

* Windows 10
* Python 3.7
* MySQL 5.7 (Banco de Dados)
* TensorFlow 0.9
* Pandas 0.21

---

E uma vez que o código for aprovado ele deverá ser colocado no servidor de produção $C$ (máquina que irá rodar de fato a aplicação).

---

O *setup* do servidor $C$ é:

* RHEL 7.6 (Red Hat Linux)
* Python 3.6
* Cassandra 3.11 (Banco de Dados)
* TensorFlow 0.7
* Pandas 0.26

---

O Pesquisador $D$ está tentando comparar a diferença de performance entre duas versões diferentes da JVM (Java), mas não quer ter que desinstalar e instalar cada versão para cada teste que precisar realizar.

---

E agora José?

---

Temos um problema de reproducibilidade e isolamento de ambientes de execução.

# Possíveis soluções:

* **Solução 1**: Obrigar todos a utilizarem os mesmos softwares que estão no servidor de produção
* **Problemas da solução 1**:
  * Servidores tendem a utilizar versões antigas e estáveis de software, o que pode atrapalhar os pesquisadores
  * Nem sempre é possível usar para desenvolvimento o que se usa em produção (licenças, interface com o usuário, demanda computacional etc)
  * Restringir pesquisadores e desenvolvedores pode resultar na fuga de capital humano qualificado

---

* **Solução 2**: Utilizar *máquinas* virtuais que espelhem o setup de produção
* **Problemas da solução 2**:
  * Máquinas virtuais são grandes (~10GB) e consomem bastante memória (~6GB) por si só
  * Versionamento (controle de versões) de máquinas virtuais não é uma tarefa simples (arquivos binários)
  * A interação entre a máquina hopedeira e a máquina hóspede (máquina virtualizada) nem sempre é simples (arquivos, rede, *clipboard* etc)

# **Docker** ao resgate

O *Docker* tenta solucionar este problema criando "máquinas virtuais" compactas, flexíveis e reutilizáveis.

---

O *Docker* utiliza o próprio *kernel* (a "base") do sistema operacional para executar as aplicações das máquinas virtualizadas.

![](img/vmvsdocker.jpg)

---

Os pricipais conceitos do *Docker* são:

* **Imagens**: instruções de como construir os containers
* ***Containers***: as "máquinas virtuais" já construídas a partir dos containers
* **Volumes**: pastas no computador hospedeiro que o container irá utilizar para armazenar arquivos permanentemente
* **Redes**: as sub-redes das quais os containers farão parte

---

# Imagens

São as "plantas" que serão utilizadas para construir os *containers*

---

São contruídas a partir de outras imagens que estão disponíveis no repositório público do Docker (entitulado [Docker Hub](http://hub.docker.com))

---

## Imagens de sistemas operacionais "puros"

![](img/hub-os.png)

---

## Imagens de sistemas operacionais com linguagens pré-instaladas

![](img/hub-languages.png)

---

## Imagens de sistemas operacionais com bancos de dados pré-instalados

![](img/hub-db.png)

---

Ex: Se eu quiser construir uma imagem para um continer Linux que irá fazer *webscrapping* utilizando Celery eu posso criar a imagem:

* A partir da imagem de um Linux puro (Alpine, Ubuntu etc)
* A partir da imagem oficial do Python (que por sua vez foi criada a partir da imagem de um Linux puro)
* A partir de uma imagem que já tenha Celery instalado e configurado

---

Trechos do `Dockerfile` do *MySQL*

---

```bash
# Usando outra imagem como ponto de partida
FROM debian:stretch-slim # ...
# Executando comandos para instalar pacotes
RUN apt-get update && # ...
# Definindo variáveis de ambiente
ENV GOSU_VERSION 1.7 # ...
# Expondo uma das pastas para o hospedeiro
VOLUME /var/lib/mysql # ...
# Copiando arquivos para a imagem
COPY config/ /etc/mysql/ # ...
# Expondo a porta 3306 para o hospedeiro
EXPOSE 3306 33060 # ...
# Executando o deamon do MySQL
CMD ["mysqld"]
```

Fonte: [MySQL Docker File](https://github.com/docker-library/mysql/blob/a7a737f1eb44db467c85c8229df9d886dd63460e/8.0/Dockerfile)

---

Esses comandos serão executados toda vez que um novo container de MySQL for construído.

---

Observações importante: **o sistema de arquivo dos *containers* é volátil!**

(Isso ficará mais claro quando falarmos sobre volumes)

# *Containers*

*Containers* são instâncias de imagens.

---

* Um *container* é gerado a partir de uma imagem
* Um hospedeiro pode executar vários *containers* simultaneamente

---

Analogia: a imagem é o molde e os *containers* são os objetos criados a partir desse molde


# Volumes

Lembram-se que o sistemas de arquivos das *imagens* são efêmeros?

---

Vamos fazer um teste.

---

Vamos criar uma instância (*container*) a partir da imagem oficial do *Ubuntu*:

![](img/1.png)

---

Agora que o *container* está rodando vamos acessar o container, criar um arquivo o arquivo `/root/file.txt` e depois parar o container.

![](img/2.png)

---

Reiniciando o *container*, acessando-o e procurando pelo arquivo temos uma surpresa:

![](img/3.png)

---

Os containers são como arquivos binários de programas que não podem ser modificados permanentemente.

---

E agora? Vamos ter que deixar nosso container de banco de dados rodando eternamente para não perder os dados?


---

Não.

---

Vamos usar ***Volumes***!

---

Volumes são pastas do sistema hospedeiro que "conectamos" (montamos) ao sistema de arquivo do container, dessa forma quando ele escrever nessas pastas ele estará escrevendo no sistema de arquivos da máquina hospedeira.

---

*Talk is cheap, show me the code!*

---

Vamos criar outro container, dando um nome a ele (para facilitar nossa vida) e montando a pasta `~/Downloads/volume_do_ubuntu` da máquina hospedeira na pasta `/root` do container e repetir o nosso experimento

---

![](img/4.png)

---

![](img/5.png)

---

É isso que fazemos com containers de bancos de dados: os arquivos utilizados pelas aplicações de banco de dados são armazenados em volumes no sistema hospedeiro.

# Networks

Containers participam de uma rede só deles

---

Para que outros sistemas consigam se comunicar com eles é necessário conectar portas dos containers a portas da máquina hospedeira (isso ficará mais claro à frente)

---

Você pode estar pensando: Solucionamos um problema criando outro: toda vez que eu for rodar minhas aplicações terei que digitar dezenas de linhas de comandos para "subir" e "descer" os containers

---

Chamamos o gerenciamento de containers de **orquestração**

# As soluções de orquestração de containers

* *Docker Compose*
* *Docker Swarm*
* *Kubernetes*

---

Chega de bla bla bla, vamos a um exemplo: o servidor de `luizsol.com`

---

# Topologia `luizsol.com`

---

![](img/blog.png)

---

Toda essa arquitetura de rede pode ser reproduzida em menos de 2 minutos por qualquer pessoa em qualquer sistema que tenha *Docker* instalado e acesso à internet com o comando:

```bash
docker-compose up
```

---

E todos os arquivos necessários para isso são arquivos de texto que estão armazenados e versionados em um repositório

![](img/repo.png)

# Concluindo

* *Docker* é uma plataforma que oferece alta simplicidade, flexibilidade e reproducibilidade de ambientes de aplicações
* Vantages:
  * Baixo *overhead*
  * Demanda pouco espaço no disco e na memória
  * Toda o controle e configuração é feita via arquivos de texto, viabilizando versionamento
  * *Industry Standard*
  * Transforma um sistema de várias partes complexas em uma solução *plug-and-play*
* Desvantagens:
  * Não é trivial de se aprender
  * Exige algum nível de conhecimeto do ambiente Linux (na maioria dos casos)
  * A fase inicial de configuração pode ser sofrida
